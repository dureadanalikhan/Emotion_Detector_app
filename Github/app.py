# -*- coding: utf-8 -*-
"""Emotion_detector_app.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1uXtlFh53eYUXx7UBxwULZ4WIg8wl9JKK
"""

import streamlit as st
import numpy as np
import cv2
from PIL import Image
import tensorflow as tf
from tensorflow import keras
import plotly.graph_objects as go

# ==============================================================
# PAGE CONFIG
# ==============================================================
st.set_page_config(
    page_title="Emotion Detection",
    page_icon="ðŸ˜Š",
    layout="wide"
)

# ==============================================================
# LOAD MODEL (with caching)
# ==============================================================
@st.cache_resource
def load_model():
    """Load the trained emotion detection model"""
    try:
        # Try loading .keras format first
        model = keras.models.load_model('best_model.keras')
        return model
    except:
        try:
            # Fallback to .h5 format
            model = keras.models.load_model('best_model.h5')
            return model
        except Exception as e:
            st.error(f"Error loading model: {e}")
            st.info("Please make sure 'best_model.keras' or 'best_model.h5' is in the same directory as this script.")
            return None

# Emotion labels
EMOTION_LABELS = {
    0: "Angry",
    1: "Disgust",
    2: "Fear",
    3: "Happy",
    4: "Neutral",
    5: "Sad",
    6: "Surprise"
}

# Emotion emojis for visual appeal
EMOTION_EMOJIS = {
    "Angry": "ðŸ˜ ",
    "Disgust": "ðŸ¤¢",
    "Fear": "ðŸ˜¨",
    "Happy": "ðŸ˜Š",
    "Neutral": "ðŸ˜",
    "Sad": "ðŸ˜¢",
    "Surprise": "ðŸ˜²"
}

# ==============================================================
# PREPROCESSING FUNCTION
# ==============================================================
def preprocess_image(image):
    """
    Preprocess image for model prediction
    - Convert to grayscale
    - Resize to 48x48
    - Normalize pixel values
    """
    # Convert PIL Image to numpy array
    img_array = np.array(image)

    # Convert to grayscale if needed
    if len(img_array.shape) == 3:
        img_gray = cv2.cvtColor(img_array, cv2.COLOR_RGB2GRAY)
    else:
        img_gray = img_array

    # Resize to 48x48
    img_resized = cv2.resize(img_gray, (48, 48))

    # Normalize to [0, 1]
    img_normalized = img_resized / 255.0

    # Reshape for model input (1, 48, 48, 1)
    img_input = img_normalized.reshape(1, 48, 48, 1)

    return img_input, img_resized

# ==============================================================
# PREDICTION FUNCTION
# ==============================================================
def predict_emotion(model, image):
    """Predict emotion from image"""
    preprocessed_img, display_img = preprocess_image(image)

    # Make prediction
    predictions = model.predict(preprocessed_img, verbose=0)

    # Get probabilities for each emotion
    emotion_probs = {EMOTION_LABELS[i]: float(predictions[0][i]) for i in range(7)}

    # Get top prediction
    predicted_class = np.argmax(predictions[0])
    predicted_emotion = EMOTION_LABELS[predicted_class]
    confidence = float(predictions[0][predicted_class])

    return predicted_emotion, confidence, emotion_probs, display_img

# ==============================================================
# VISUALIZATION FUNCTION
# ==============================================================
def create_probability_chart(emotion_probs):
    """Create a horizontal bar chart for emotion probabilities"""
    emotions = list(emotion_probs.keys())
    probabilities = [emotion_probs[e] * 100 for e in emotions]

    # Add emojis to labels
    labels = [f"{EMOTION_EMOJIS[e]} {e}" for e in emotions]

    # Sort by probability
    sorted_data = sorted(zip(labels, probabilities), key=lambda x: x[1], reverse=True)
    labels, probabilities = zip(*sorted_data)

    # Create color scale (highlight top prediction)
    colors = ['#FF6B6B' if i == 0 else '#4ECDC4' for i in range(len(labels))]

    fig = go.Figure(go.Bar(
        x=probabilities,
        y=labels,
        orientation='h',
        marker=dict(color=colors),
        text=[f'{p:.1f}%' for p in probabilities],
        textposition='auto',
    ))

    fig.update_layout(
        title="Emotion Confidence Scores",
        xaxis_title="Confidence (%)",
        yaxis_title="Emotion",
        height=400,
        showlegend=False,
        template="plotly_white"
    )

    return fig

# ==============================================================
# MAIN APP
# ==============================================================
def main():
    # Header
    st.title("ðŸ˜Š Emotion Detection using CNN")
    st.markdown("Upload an image or use your webcam to detect facial emotions in real-time!")

    # Load model
    model = load_model()

    if model is None:
        st.stop()

    # Sidebar
    st.sidebar.header("About")
    st.sidebar.info(
        """
        This app uses a Convolutional Neural Network (CNN) trained on the FER-2013 dataset
        to detect 7 different emotions:

        ðŸ˜  Angry | ðŸ¤¢ Disgust | ðŸ˜¨ Fear | ðŸ˜Š Happy | ðŸ˜ Neutral | ðŸ˜¢ Sad | ðŸ˜² Surprise

        **Model Performance:**
        - Test Accuracy: 61%
        - Best at detecting: Happy, Surprise
        - Training: 60 epochs on ~28k images
        """
    )

    st.sidebar.header("How to Use")
    st.sidebar.markdown(
        """
        1. Choose input method (Upload or Webcam)
        2. Provide an image with a clear face
        3. Click 'Predict Emotion'
        4. View results and confidence scores

        **Tips for best results:**
        - Use well-lit images
        - Ensure face is clearly visible
        - Front-facing photos work best
        """
    )

    # Main content
    col1, col2 = st.columns([1, 1])

    with col1:
        st.subheader("ðŸ“¤ Input")

        # Input method selection
        input_method = st.radio(
            "Choose input method:",
            ["Upload Image", "Capture from Webcam"],
            horizontal=True
        )

        image = None

        if input_method == "Upload Image":
            uploaded_file = st.file_uploader(
                "Choose an image...",
                type=['jpg', 'jpeg', 'png'],
                help="Upload a clear image with a visible face"
            )

            if uploaded_file is not None:
                image = Image.open(uploaded_file)
                st.image(image, caption="Uploaded Image", use_container_width=True)

        else:  # Webcam
            camera_photo = st.camera_input("Take a photo")

            if camera_photo is not None:
                image = Image.open(camera_photo)
                st.image(image, caption="Captured Image", use_container_width=True)

        # Predict button
        predict_button = st.button(" Predict Emotion", type="primary", use_container_width=True)

    with col2:
        st.subheader("ðŸ“Š Results")

        if predict_button and image is not None:
            with st.spinner("Analyzing emotion..."):
                # Make prediction
                predicted_emotion, confidence, emotion_probs, processed_img = predict_emotion(model, image)

                # Display results
                st.success("Prediction Complete!")

                # Show predicted emotion with emoji
                st.markdown(f"### Detected Emotion: {EMOTION_EMOJIS[predicted_emotion]} **{predicted_emotion}**")
                st.markdown(f"**Confidence:** {confidence * 100:.2f}%")

                # Confidence interpretation
                if confidence > 0.7:
                    st.info(" High confidence prediction")
                elif confidence > 0.4:
                    st.warning(" Moderate confidence - emotion might be ambiguous")
                else:
                    st.error("Low confidence - image quality or multiple emotions detected")

                # Show processed image
                with st.expander("View Preprocessed Image (48x48 grayscale)"):
                    st.image(processed_img, caption="Model Input", width=200)

                # Probability chart
                st.plotly_chart(create_probability_chart(emotion_probs), use_container_width=True)

                # Top 3 predictions
                sorted_emotions = sorted(emotion_probs.items(), key=lambda x: x[1], reverse=True)
                st.markdown("#### Top 3 Predictions:")
                for i, (emotion, prob) in enumerate(sorted_emotions[:3], 1):
                    st.write(f"{i}. {EMOTION_EMOJIS[emotion]} **{emotion}**: {prob * 100:.2f}%")

        elif predict_button and image is None:
            st.warning(" Please upload an image or capture one from webcam first!")
        else:
            st.info(" Upload an image or capture from webcam to get started")

    # Footer
    st.markdown("---")
    st.markdown(
        """
        <div style='text-align: center'>
            <p>Built using Streamlit | Model: CNN trained on FER-2013</p>
        </div>
        """,
        unsafe_allow_html=True
    )

if __name__ == "__main__":
    main()